{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'descartes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZipFile\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdescartes\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'descartes'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import shapefile\n",
    "from shapely.geometry import shape, mapping, Point, Polygon\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import descartes\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.12.1-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from geopandas) (1.4.2)\n",
      "Collecting pyproj>=2.6.1.post1\n",
      "  Downloading pyproj-3.4.0-cp39-cp39-win_amd64.whl (4.8 MB)\n",
      "Collecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.22-cp39-cp39-win_amd64.whl (21.7 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: shapely>=1.7 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from geopandas) (1.8.5.post1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from fiona>=1.8->geopandas) (61.2.0)\n",
      "Requirement already satisfied: attrs>=17 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
      "Collecting click-plugins>=1.0\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: six>=1.7 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from fiona>=1.8->geopandas) (1.16.0)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from fiona>=1.8->geopandas) (8.0.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from fiona>=1.8->geopandas) (2022.9.24)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from click>=4.0->fiona>=1.8->geopandas) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from pandas>=1.0.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from pandas>=1.0.0->geopandas) (1.22.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\envs\\newenv\\lib\\site-packages (from packaging->geopandas) (3.0.4)\n",
      "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.22 geopandas-0.12.1 munch-2.5.0 pyproj-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading Shapely-1.8.5.post1-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-1.8.5.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyshp\n",
      "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
      "Installing collected packages: pyshp\n",
      "Successfully installed pyshp-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyshp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = 'Data/test_data_050519.xlsx'\n",
    "output_csv_path = 'Data/columbus_training_test_050519.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tornado Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for tornado disasters in Columbus, 1950-2010: http://www.usa.com/columbus-oh-natural-disasters-extremes.htm\n",
    "tornado_df = pd.read_csv(\"Data/HistoricalTornadoEvents.csv\")\n",
    "tornado_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "def deg_to_decimal(d, m, s, direction):\n",
    "    res = int(d) + float(m)/60 + float(s)/3600\n",
    "    if direction in ('S','W'):\n",
    "        res *= -1\n",
    "    return res\n",
    "\n",
    "def tornado_df_coords(str_col):\n",
    "    tornado_arr = np.array(tornado_df[str_col])\n",
    "    coords = [coord.split(\" / \") for coord in tornado_arr]\n",
    "\n",
    "    p = re.compile('(\\d+)Â°(\\d+)\\'([N|S|E|W])')\n",
    "    coords_new = []\n",
    "    for lat_long in coords:\n",
    "        lat = p.match(lat_long[0])\n",
    "        lat_dd = deg_to_decimal(lat.group(1), lat.group(2), 0, lat.group(3))\n",
    "\n",
    "        long = p.match(lat_long[1])\n",
    "        long_dd = deg_to_decimal(long.group(1), long.group(2), 0, long.group(3))\n",
    "        \n",
    "        coords_new.append([lat_dd, long_dd])\n",
    "\n",
    "    return coords_new\n",
    "\n",
    "starts = tornado_df_coords('Start Lat/Log')\n",
    "ends = tornado_df_coords('End Lat/Log')\n",
    "\n",
    "def convert(coords):\n",
    "    lat = [coords[i][0] for i in range(len(coords))]\n",
    "    long = [coords[i][1] for i in range(len(coords))]\n",
    "    dist = 2*list(tornado_df[\"Distance (miles)\"])\n",
    "    magnitude = 2*list(tornado_df[\"Magnitude\"])\n",
    "    \n",
    "    p = re.compile('(\\d+.\\d+)\\sMile[s]*')\n",
    "    length = [float(p.match(l).group(1)) for l in 2*list(tornado_df[\"Length\"])]\n",
    "    \n",
    "    d = {\"Lat\": lat, \"Long\": long, \"Distance\": dist, \"Magnitude\": magnitude, \"Length\": length}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "\n",
    "dist_mag_tornado_df = convert(starts+ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest = pd.read_excel(train_test_path) # traintest has 158 rows\n",
    "\n",
    "# find matching coordinates with smallest distance\n",
    "def calc_smallest_dist_tornado(comp):\n",
    "    d = []\n",
    "    vals = {\"Distance\": [], \"Magnitude\": [], \"Length\": []}\n",
    "    km_per_mi = 1.60934\n",
    "    for outer in range(len(traintest)):\n",
    "        smallest = np.inf\n",
    "        tornado_dist = 0\n",
    "        tornado_mag = 0\n",
    "        tornado_length = 0\n",
    "#         traintest_coord = LatLon.LatLon(Latitude(traintest.loc[outer, 'Latitude']), Longitude(traintest.loc[outer, 'Longitude']))\n",
    "#         comp_coord = LatLon(Latitude(comp.loc[ctr, 'Lat']), Longitude(comp.loc[ctr, 'Long']))\n",
    "        for ctr in range(len(comp)):\n",
    "            dist = np.sqrt(((traintest.loc[outer, 'Latitude'] - comp.loc[ctr, 'Lat']) ** 2) + ((traintest.loc[outer, 'Longitude'] - comp.loc[ctr, 'Long']) ** 2))\n",
    "#             dist = traintest_coord.distance(comp_coord) * km_per_mi\n",
    "            if dist < smallest:\n",
    "                smallest = dist\n",
    "                tornado_dist = comp.loc[ctr, 'Distance']\n",
    "                tornado_mag = int(comp.loc[ctr, 'Magnitude'])\n",
    "                tornado_length = comp.loc[ctr, 'Length']\n",
    "        d.append(smallest)\n",
    "        vals[\"Distance\"].append(tornado_dist)\n",
    "        vals[\"Magnitude\"].append(tornado_mag)\n",
    "        vals[\"Length\"].append(tornado_length)\n",
    "    return (d, vals)\n",
    "\n",
    "distances, vals = calc_smallest_dist_tornado(dist_mag_tornado_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vals = {\"Distance\": [], \"Magnitude\": []}\n",
    "\n",
    "# if dist < tornado_length/69, leave as is, or it will be None (further than 1 mile)\n",
    "miles_per_deg = 69\n",
    "for ctr in range(len(distances)):\n",
    "    miles_within = vals[\"Length\"][ctr]\n",
    "    if distances[ctr] < miles_within/miles_per_deg:\n",
    "        final_vals[\"Distance\"].append(vals[\"Distance\"][ctr])\n",
    "        final_vals[\"Magnitude\"].append(vals[\"Magnitude\"][ctr])\n",
    "    else:\n",
    "        final_vals[\"Distance\"].append(0)\n",
    "        final_vals[\"Magnitude\"].append(0)\n",
    "    \n",
    "# df here is doing to be the final DF with distance/magnitude for each point in train/test data\n",
    "# d = {\"Lat\": traintest['Latitude'], \"Long\": traintest['Longitude'], \"Distance\": final_vals[\"Distance\"], \"Magnitude\": final_vals[\"Magnitude\"]}\n",
    "\n",
    "# unnecessary\n",
    "# df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given GEOID, return series that contains the Area and geometry of GEOID\n",
    "def getMatchingGEOIDData(geoid):\n",
    "    return gdf[gdf[\"GEOID\"] == int(geoid)][[\"Area\", \"geometry\"]]\n",
    "\n",
    "# Return the county name where GEOID is in \n",
    "def geoidToCountyLatLong(geoid):\n",
    "    countyCode = int(geoid / 10000000)\n",
    "    return county_data[county_data[\"GEOID\"] == countyCode][[\"NAME\"]]\n",
    "\n",
    "# Return the GEOID of the given coordinates\n",
    "def pointToGeoid(long, lat):\n",
    "    type1 = type(long)\n",
    "    type2 = type(lat)\n",
    "    assert(type1 == type2), \"Parameters must be the same type\"\n",
    "    _pnts = []\n",
    "    \n",
    "    if (type1 == list):\n",
    "        assert(len(long) == len(lat)), \"Parameters must have same length\"\n",
    "        for i in range(len(long)):\n",
    "            _pnts.append(Point(long[i], lat[i]))\n",
    "    else:\n",
    "        _pnts.append(Point(long, lat))\n",
    "        \n",
    "    pnts = gpd.GeoDataFrame(geometry=_pnts)\n",
    "    for _, row in gdf_original.iterrows():\n",
    "        if pnts.within(row.geometry)[0]:\n",
    "            return row.GEOID\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "def getGeoidPopulation(geoid):\n",
    "    population = ohio_population_data[ohio_population_data['GEOID'] == int(geoid)][\"2010 Total Population\"]\n",
    "    return population[0] if population.size == 1 else 0.0\n",
    "\n",
    "def getGeoidArea(geoid):\n",
    "    area = ohio_population_data[ohio_population_data['GEOID'] == int(geoid)][\"Area (square miles)\"]\n",
    "    return area[0] if area.size == 1 else 0.0\n",
    "\n",
    "def getGeoidCountyName(geoid):\n",
    "    county = ohio_population_data[ohio_population_data['GEOID'] == int(geoid)][\"CountyNames\"]\n",
    "    return county[0] if county.size == 1 else \"\"\n",
    "\n",
    "# Returns copy of df with GEOID and data relevant to GEOID to df\n",
    "# If lat long not associated with a GEOID, population and area = 0.0 and CountyName = \"\" \n",
    "# Precondition: df is a dataframe\n",
    "def addGeoidColumns(df):\n",
    "    assert('Longitude' in df.columns), \"Cannot find longitude column\"\n",
    "    assert('Latitude' in df.columns), \"Cannot find latitude column\"\n",
    "    df_copy = df.copy(deep=False)\n",
    "    \n",
    "    geoidData = df_copy.apply(lambda x: pointToGeoid(x['Longitude'], x['Latitude']), axis=1)\n",
    "    df_copy = df_copy.assign(GEOID=geoidData.values)\n",
    "    populationData = df_copy.apply(lambda x: getGeoidPopulation(x['GEOID']), axis=1)\n",
    "    areaData = df_copy.apply(lambda x: getGeoidArea(x['GEOID']), axis=1)\n",
    "    #countyData = df_copy.apply(lambda x: getGeoidCountyName(x['GEOID']), axis=1)\n",
    "    df['Pop_Den'] = populationData / areaData\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(data \u001b[38;5;241m=\u001b[39m attributes, geometry \u001b[38;5;241m=\u001b[39m geometry)[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALAND10\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEOID10\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     19\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mrename(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALAND10\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArea\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEOID10\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m---> 20\u001b[0m gdf\u001b[38;5;241m.\u001b[39mGEOID \u001b[38;5;241m=\u001b[39m \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGEOID\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf[gdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(geoids)] \u001b[38;5;66;03m# Only get data on GEOIDs that match census data above\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Latitude/Longitude ordering is switched, swap it back and add it as the \"geometry\" column\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   5908\u001b[0m     ]\n\u001b[0;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1154\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1151\u001b[0m \n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# work around NumPy brokenness, #1987\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[1;32m-> 1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype_intsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\newEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "census_data = pd.read_excel(\"Data/Columbus_Population.xlsx\").iloc[:,0:2]\n",
    "geoids = census_data.iloc[:,0]\n",
    "\n",
    "# CREDIT TO http://andrewgaidus.com/Reading_Zipped_Shapefiles/, used to parse census data taken from\n",
    "# .dbf, .prj, .shp, and .shx files\n",
    "zipFile = ZipFile(\"Data/ohio_tigerfiles.zip\")\n",
    "filenames = [y for y in sorted(zipFile.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \n",
    "dbf, prj, shp, shx = [BytesIO(zipFile.read(filename)) for filename in filenames]\n",
    "\n",
    "reader = shapefile.Reader(shp=shp, shx=shx, dbf=dbf)\n",
    "attributes, geometry = [], []\n",
    "field_names = [field[0] for field in reader.fields[1:]]  \n",
    "for row in reader.shapeRecords():  \n",
    "    geometry.append(shape(row.shape.__geo_interface__))\n",
    "    attributes.append(dict(zip(field_names, row.record)))\n",
    "    \n",
    "# Put tigerfiles into GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(data = attributes, geometry = geometry)[[\"ALAND10\", \"GEOID10\", \"geometry\"]]\n",
    "gdf = gdf.rename(index=str, columns={\"ALAND10\": \"Area\", \"GEOID10\": \"GEOID\"})\n",
    "gdf.GEOID = gdf.GEOID.astype(int)\n",
    "gdf = gdf[gdf[\"GEOID\"].isin(geoids)] # Only get data on GEOIDs that match census data above\n",
    "\n",
    "# Latitude/Longitude ordering is switched, swap it back and add it as the \"geometry\" column\n",
    "block_coord_array = []\n",
    "for _, row in gdf.iterrows():\n",
    "    row_coord_array = []\n",
    "    for coord in mapping(row['geometry'])['coordinates'][0]:\n",
    "        correct_coord = reversed(coord)\n",
    "        row_coord_array.append(list(correct_coord))\n",
    "    \n",
    "    block_coord_array.append(row_coord_array)\n",
    "    \n",
    "gdf_original = gdf.copy(deep=True)\n",
    "gdf[\"geometry\"] = pd.Series(block_coord_array, index=gdf.index)\n",
    "\n",
    "blockRows = geoids.apply(getMatchingGEOIDData) #An array of DF rows\n",
    "\n",
    "block_df = pd.DataFrame()\n",
    "for row in blockRows:\n",
    "    block_df = block_df.append(row, ignore_index=True)\n",
    "    \n",
    "ohio_population_data = census_data.join(block_df)\n",
    "\n",
    "county_data = pd.read_excel(\"Data/Ohio_GEOID_Conversion.xlsx\").iloc[:,1:4]\n",
    "\n",
    "# geoids is only restricted to columbus\n",
    "countyRows = geoids.apply(geoidToCountyLatLong)\n",
    "county_df = pd.DataFrame()\n",
    "for county in countyRows:\n",
    "    county_df = county_df.append(county, ignore_index=True)\n",
    "    \n",
    "ohio_population_data[\"CountyNames\"] = pd.Series(county_df.NAME.values, index=ohio_population_data.index)\n",
    "ohio_population_data = ohio_population_data.rename(index=str, columns={\"Area\": \"Area (square miles)\"})\n",
    "\n",
    "# Convert square meters to square miles\n",
    "ohio_population_data[\"Area (square miles)\"] = ohio_population_data[\"Area (square miles)\"] / 2589988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_popln = pd.read_csv('Data/Ohio_Population_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>2010 Total Population</th>\n",
       "      <th>Area (square miles)</th>\n",
       "      <th>geometry</th>\n",
       "      <th>CountyNames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390410101003</td>\n",
       "      <td>2258</td>\n",
       "      <td>0.444847</td>\n",
       "      <td>[[40.303889, -83.082549], [40.303813, -83.0823...</td>\n",
       "      <td>Delaware County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>390410102002</td>\n",
       "      <td>1002</td>\n",
       "      <td>0.369116</td>\n",
       "      <td>[[40.297744, -83.046934], [40.296802, -83.0467...</td>\n",
       "      <td>Delaware County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390410102003</td>\n",
       "      <td>2692</td>\n",
       "      <td>1.485314</td>\n",
       "      <td>[[40.297655999999996, -83.046442], [40.2977, -...</td>\n",
       "      <td>Delaware County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>390410102004</td>\n",
       "      <td>927</td>\n",
       "      <td>0.936026</td>\n",
       "      <td>[[40.2826, -83.061833], [40.282747, -83.061826...</td>\n",
       "      <td>Delaware County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>390410105201</td>\n",
       "      <td>229</td>\n",
       "      <td>2.287126</td>\n",
       "      <td>[[40.267752, -83.11309299999999], [40.267989, ...</td>\n",
       "      <td>Delaware County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID  2010 Total Population  Area (square miles)  \\\n",
       "0  390410101003                   2258             0.444847   \n",
       "1  390410102002                   1002             0.369116   \n",
       "2  390410102003                   2692             1.485314   \n",
       "3  390410102004                    927             0.936026   \n",
       "4  390410105201                    229             2.287126   \n",
       "\n",
       "                                            geometry      CountyNames  \n",
       "0  [[40.303889, -83.082549], [40.303813, -83.0823...  Delaware County  \n",
       "1  [[40.297744, -83.046934], [40.296802, -83.0467...  Delaware County  \n",
       "2  [[40.297655999999996, -83.046442], [40.2977, -...  Delaware County  \n",
       "3  [[40.2826, -83.061833], [40.282747, -83.061826...  Delaware County  \n",
       "4  [[40.267752, -83.11309299999999], [40.267989, ...  Delaware County  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_popln.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>2010 Total Population</th>\n",
       "      <th>2010 White Population</th>\n",
       "      <th>2010 African American Population</th>\n",
       "      <th>2010 Asian Population</th>\n",
       "      <th>2010 Other Races Population</th>\n",
       "      <th>2010 Hispanic Population</th>\n",
       "      <th>2010 Total Households</th>\n",
       "      <th>2010 Occupied Households</th>\n",
       "      <th>2010 Vacant Households</th>\n",
       "      <th>2000 Total Population</th>\n",
       "      <th>2000 White Population</th>\n",
       "      <th>2000 African American Population</th>\n",
       "      <th>2000 Asian Population</th>\n",
       "      <th>2000 Other Races Population</th>\n",
       "      <th>2000 Total Housing Units</th>\n",
       "      <th>2000 Occupied Housing Units</th>\n",
       "      <th>2000 Vacant Housing Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390410101003</td>\n",
       "      <td>2258</td>\n",
       "      <td>1896</td>\n",
       "      <td>156</td>\n",
       "      <td>129</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>449</td>\n",
       "      <td>397</td>\n",
       "      <td>52</td>\n",
       "      <td>2579</td>\n",
       "      <td>2305</td>\n",
       "      <td>157</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>447</td>\n",
       "      <td>414</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>390410102002</td>\n",
       "      <td>1002</td>\n",
       "      <td>953</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>454</td>\n",
       "      <td>423</td>\n",
       "      <td>31</td>\n",
       "      <td>1085</td>\n",
       "      <td>1038</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>443</td>\n",
       "      <td>425</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390410102003</td>\n",
       "      <td>2692</td>\n",
       "      <td>2446</td>\n",
       "      <td>127</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>951</td>\n",
       "      <td>932</td>\n",
       "      <td>19</td>\n",
       "      <td>1180</td>\n",
       "      <td>1137</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>524</td>\n",
       "      <td>439</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>390410102004</td>\n",
       "      <td>927</td>\n",
       "      <td>834</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>369</td>\n",
       "      <td>345</td>\n",
       "      <td>24</td>\n",
       "      <td>898</td>\n",
       "      <td>838</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>391</td>\n",
       "      <td>346</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>390410105201</td>\n",
       "      <td>229</td>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>218</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID  2010 Total Population  2010 White Population  \\\n",
       "0  390410101003                   2258                   1896   \n",
       "1  390410102002                   1002                    953   \n",
       "2  390410102003                   2692                   2446   \n",
       "3  390410102004                    927                    834   \n",
       "4  390410105201                    229                    217   \n",
       "\n",
       "   2010 African American Population  2010 Asian Population  \\\n",
       "0                               156                    129   \n",
       "1                                18                      3   \n",
       "2                               127                     30   \n",
       "3                                43                      1   \n",
       "4                                 3                      2   \n",
       "\n",
       "   2010 Other Races Population  2010 Hispanic Population  \\\n",
       "0                           77                        63   \n",
       "1                           28                        24   \n",
       "2                           89                        82   \n",
       "3                           49                        33   \n",
       "4                            7                         3   \n",
       "\n",
       "   2010 Total Households  2010 Occupied Households  2010 Vacant Households  \\\n",
       "0                    449                       397                      52   \n",
       "1                    454                       423                      31   \n",
       "2                    951                       932                      19   \n",
       "3                    369                       345                      24   \n",
       "4                    107                        98                       9   \n",
       "\n",
       "   2000 Total Population  2000 White Population  \\\n",
       "0                   2579                   2305   \n",
       "1                   1085                   1038   \n",
       "2                   1180                   1137   \n",
       "3                    898                    838   \n",
       "4                    218                    211   \n",
       "\n",
       "   2000 African American Population  2000 Asian Population  \\\n",
       "0                               157                     66   \n",
       "1                                13                      1   \n",
       "2                                23                      9   \n",
       "3                                18                      4   \n",
       "4                                 0                      0   \n",
       "\n",
       "   2000 Other Races Population  2000 Total Housing Units  \\\n",
       "0                           51                       447   \n",
       "1                           33                       443   \n",
       "2                           11                       524   \n",
       "3                           38                       391   \n",
       "4                            7                       102   \n",
       "\n",
       "   2000 Occupied Housing Units  2000 Vacant Housing Units  \n",
       "0                          414                         33  \n",
       "1                          425                         18  \n",
       "2                          439                         85  \n",
       "3                          346                         45  \n",
       "4                           98                          4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_colm  = pd.read_excel('Data/Columbus_Population.xlsx')\n",
    "df_colm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USPS</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>ANSICODE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>ALAND_SQMI</th>\n",
       "      <th>AWATER_SQMI</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OH</td>\n",
       "      <td>39001</td>\n",
       "      <td>1074014</td>\n",
       "      <td>Adams County</td>\n",
       "      <td>1512208934</td>\n",
       "      <td>6165939</td>\n",
       "      <td>583.867</td>\n",
       "      <td>2.381</td>\n",
       "      <td>38.834468</td>\n",
       "      <td>-83.478082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>39003</td>\n",
       "      <td>1074015</td>\n",
       "      <td>Allen County</td>\n",
       "      <td>1042470095</td>\n",
       "      <td>11266164</td>\n",
       "      <td>402.500</td>\n",
       "      <td>4.350</td>\n",
       "      <td>40.771627</td>\n",
       "      <td>-84.106103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OH</td>\n",
       "      <td>39005</td>\n",
       "      <td>1074016</td>\n",
       "      <td>Ashland County</td>\n",
       "      <td>1095444134</td>\n",
       "      <td>9962880</td>\n",
       "      <td>422.953</td>\n",
       "      <td>3.847</td>\n",
       "      <td>40.843273</td>\n",
       "      <td>-82.270127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>39007</td>\n",
       "      <td>1074017</td>\n",
       "      <td>Ashtabula County</td>\n",
       "      <td>1818360011</td>\n",
       "      <td>1724498213</td>\n",
       "      <td>702.073</td>\n",
       "      <td>665.833</td>\n",
       "      <td>41.906637</td>\n",
       "      <td>-80.745592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OH</td>\n",
       "      <td>39009</td>\n",
       "      <td>1074018</td>\n",
       "      <td>Athens County</td>\n",
       "      <td>1304383737</td>\n",
       "      <td>12463875</td>\n",
       "      <td>503.625</td>\n",
       "      <td>4.812</td>\n",
       "      <td>39.332604</td>\n",
       "      <td>-82.045844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  USPS  GEOID  ANSICODE              NAME       ALAND      AWATER  ALAND_SQMI  \\\n",
       "0   OH  39001   1074014      Adams County  1512208934     6165939     583.867   \n",
       "1   OH  39003   1074015      Allen County  1042470095    11266164     402.500   \n",
       "2   OH  39005   1074016    Ashland County  1095444134     9962880     422.953   \n",
       "3   OH  39007   1074017  Ashtabula County  1818360011  1724498213     702.073   \n",
       "4   OH  39009   1074018     Athens County  1304383737    12463875     503.625   \n",
       "\n",
       "   AWATER_SQMI   INTPTLAT  INTPTLONG  \n",
       "0        2.381  38.834468 -83.478082  \n",
       "1        4.350  40.771627 -84.106103  \n",
       "2        3.847  40.843273 -82.270127  \n",
       "3      665.833  41.906637 -80.745592  \n",
       "4        4.812  39.332604 -82.045844  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= pd.read_excel('Data/Ohio_GEOID_Conversion.xlsx')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here, endingDF is DF with population density for each coordinate\n",
    "# test_data = pd.read_csv(\"./Data/Training.csv\")\n",
    "# endingDF = addGeoidColumns(test_data)\n",
    "# endingDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point of Interest Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points of Interest file - includes all popular areas in Columbus, OH\n",
    "# Source: http://opendata.columbus.gov/datasets/86458e5d8a264dff9204518e109c0f93_10?geometry=-83.926%2C39.846%2C-82.168%2C40.214&page=7\n",
    "poi_df = pd.read_csv('Data/Points_of_Interest.csv')\n",
    "\n",
    "#drop irrelevant columns\n",
    "poi_df = poi_df.drop(['POI_SOURCE', 'WEBSITE', 'OB_GYN', 'PEDIATRICS', 'PRIMARY_CARE'], axis=1)\n",
    "\n",
    "zeros = ['Emergency', 'Medical', 'Industrial']\n",
    "ones = ['Government', 'Group Quarters', 'Education']\n",
    "twos = ['Transportation', 'Public Places', 'Retail', 'Office']\n",
    "\n",
    "poi = poi_df[['X', 'Y', 'POI_TYPE']].copy()\n",
    "\n",
    "# match all strings = 'category - subcategory' and remove the part immediately following the\n",
    "# '-' to end with 'category'\n",
    "\n",
    "new_poi = poi.replace(to_replace=r' - .*', value='', regex=True)\n",
    "new_poi['Classification'] = new_poi['POI_TYPE']\n",
    "new_poi['Classification'].replace({'Emergency': 0, 'Medical': 0, 'Industrial': 0, 'Government': 1, \n",
    "                                             'Group Quarters': 1, 'Education': 1, 'Transportation': 2, \n",
    "                                             'Public Places': 2, 'Retail': 2, 'Office': 2}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make this the previous DF generated by past cells\n",
    "traintest = pd.read_excel(train_test_path)\n",
    "distances = []\n",
    "classifications = []\n",
    "final_distances = []\n",
    "final_classifications = []\n",
    "\n",
    "# find matching coordinates with smallest distance\n",
    "def calc_smallest_dist_poi(comp):\n",
    "    d = []\n",
    "    c = []\n",
    "    outer = 0\n",
    "    while outer < len(traintest):\n",
    "        ctr = 0\n",
    "        smallest = np.inf\n",
    "        cls = 0 # 0, 1, or 2\n",
    "        while ctr < len(comp): # go through 15,000 rows\n",
    "            dist = np.sqrt(((traintest.loc[outer, 'Latitude'] - comp.loc[ctr, 'Y']) ** 2) + ((traintest.loc[outer, 'Longitude'] - comp.loc[ctr, 'X']) ** 2))\n",
    "            if dist < smallest:\n",
    "                smallest = dist\n",
    "                cls = comp.loc[ctr, 'Classification']\n",
    "            ctr += 1\n",
    "        d.append(smallest)\n",
    "        c.append(cls)\n",
    "        outer += 1\n",
    "    return (d, c)\n",
    "\n",
    "distances, classifications = calc_smallest_dist_poi(new_poi)\n",
    "\n",
    "# if dist < 1/69, leave as is, or it will be None (further than 1 mile)\n",
    "ctr = 0\n",
    "for i in distances:\n",
    "    if i < 1/69:\n",
    "        final_distances.append(i)\n",
    "        final_classifications.append(classifications[ctr])\n",
    "    else:\n",
    "        final_distances.append(None)\n",
    "        final_classifications.append(None)\n",
    "    ctr += 1\n",
    "\n",
    "# TODO: Add final_classifications as column in DF\n",
    "# final_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Police Cam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "current_df = pd.read_excel(train_test_path)\n",
    "camera_df = pd.read_csv(\"Data/Police_Crime_Cameras.csv\")\n",
    "camera_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# approximate radius of earth in km\n",
    "def distanceBetweenPoints(lat1, lon1, lat2, lon2):\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "for index, row in current_df.iterrows():\n",
    "    for index2, row2 in camera_df.iterrows():\n",
    "        current_df.set_value(index, 'Cam_Present', 0)\n",
    "        if distanceBetweenPoints(row2['LATITUDE'], row2['LONGITUDE'], row['Latitude'], row['Longitude']) < 1:\n",
    "            current_df.set_value(index, 'Cam_Present', 1)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>POI_TYPE</th>\n",
       "      <th>Pop_Den</th>\n",
       "      <th>Cam_Present</th>\n",
       "      <th>Tornado Distance</th>\n",
       "      <th>Tornado Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.866455</td>\n",
       "      <td>-82.906610</td>\n",
       "      <td>None</td>\n",
       "      <td>690.307610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.975762</td>\n",
       "      <td>-83.149522</td>\n",
       "      <td>2</td>\n",
       "      <td>562.491864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.862268</td>\n",
       "      <td>-83.085818</td>\n",
       "      <td>1</td>\n",
       "      <td>479.089092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.122173</td>\n",
       "      <td>-82.851558</td>\n",
       "      <td>None</td>\n",
       "      <td>163.109340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.963516</td>\n",
       "      <td>-83.080848</td>\n",
       "      <td>1</td>\n",
       "      <td>2494.987204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude POI_TYPE      Pop_Den  Cam_Present  Tornado Distance  \\\n",
       "0  39.866455 -82.906610     None   690.307610          0.0               0.0   \n",
       "1  39.975762 -83.149522        2   562.491864          0.0               5.2   \n",
       "2  39.862268 -83.085818        1   479.089092          0.0               0.0   \n",
       "3  40.122173 -82.851558     None   163.109340          0.0              15.2   \n",
       "4  39.963516 -83.080848        1  2494.987204          0.0              13.1   \n",
       "\n",
       "   Tornado Magnitude  \n",
       "0                  0  \n",
       "1                  3  \n",
       "2                  0  \n",
       "3                  2  \n",
       "4                  2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addFeatureData(df):\n",
    "    assert('Longitude' in df.columns), \"Cannot find longitude column\"\n",
    "    assert('Latitude' in df.columns), \"Cannot find latitude column\"\n",
    "    \n",
    "    # Add final_classifications\n",
    "    df['POI_TYPE'] = pd.Series(final_classifications, index=df.index)\n",
    "    \n",
    "    # Run addGeoidColumns\n",
    "    df = addGeoidColumns(df)\n",
    "    \n",
    "    # Add Police Camera\n",
    "    df['Cam_Present'] = pd.Series(current_df['Cam_Present'], index=df.index)\n",
    "    \n",
    "    # Add final_vals[\"Distance\"]\n",
    "    df['Tornado Distance'] = pd.Series(final_vals['Distance'], index=df.index)\n",
    "    \n",
    "    # Add final_vals[\"Magnitude\"]\n",
    "    df['Tornado Magnitude'] = pd.Series(final_vals['Magnitude'], index=df.index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "total_train_test_data = pd.read_excel(train_test_path)\n",
    "allFeatureDF = addFeatureData(total_train_test_data)\n",
    "allFeatureDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatureDF['Pop_Den'] = allFeatureDF['Pop_Den'].fillna((allFeatureDF['Pop_Den'].mean()))\n",
    "allFeatureDF['POI_TYPE'] = allFeatureDF['POI_TYPE'].replace('None', (allFeatureDF['POI_TYPE'].mode())[0])\n",
    "allFeatureDF['POI_TYPE'] = allFeatureDF['POI_TYPE'].replace(np.NaN, (allFeatureDF['POI_TYPE'].mode())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatureDF.to_csv(output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
